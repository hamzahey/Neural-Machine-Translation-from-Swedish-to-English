{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**ENGLISH TO SWEDISH**"
      ],
      "metadata": {
        "id": "VkcW-ApJzIQa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wzYCAupEeaKl"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FQHjRhg0eaKo"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from torchtext.vocab import GloVe\n",
        "import torchtext.vocab as vocab\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z34bfRuHeaKp"
      },
      "source": [
        "#**Loading data files**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PRETRAINED WORD EMBEDDINGS(GloVe)**"
      ],
      "metadata": {
        "id": "RChz1MiD0xaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove = GloVe(name='6B', dim=300)\n",
        "pretrained_embeddings = glove.vectors"
      ],
      "metadata": {
        "id": "bM5ED-Oe0wdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55956b74-2d75-4351-bbfa-60f3c0e0e89d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:53<00:00, 7471.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WE9AqPwQeaKq"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "# Assuming vocab_size is the size of your vocabulary\n",
        "vocab_size = len(glove.itos)\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LZp8N3g4eaKq"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BE6j1FFmeaKr"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # modified reading dataset to incorporate the new format\n",
        "\n",
        "    lines = []\n",
        "    with open('%s-%s.txt' % (lang1, lang2), encoding='utf-8') as file:\n",
        "      line = file.readline()\n",
        "      while line:\n",
        "\n",
        "        line = line.strip().split('\\t')\n",
        "        line = \"\\t\".join((line[1],line[3]))\n",
        "\n",
        "        lines.append(line)\n",
        "        line = file.readline()\n",
        "\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "slg1GXZjeaKr"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BHqzfBMeaKr"
      },
      "source": [
        "The full process for preparing the data is:\n",
        "\n",
        "-   Read text file and split into lines, split lines into pairs\n",
        "-   Normalize text, filter by length and content\n",
        "-   Make word lists from sentences in pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NVbcMYo2eaKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ced721d-0fce-4b6a-a1c6-1516c441b8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 40314 sentence pairs\n",
            "Trimmed to 3017 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "swe 2079\n",
            "eng 1777\n",
            "['du har helt ratt', 'you re absolutely right']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'swe', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8M6um9leaKs"
      },
      "source": [
        "#**The Seq2Seq Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**The Encoder**"
      ],
      "metadata": {
        "id": "W7_n6vvXzmM0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Sa0aNK23eaKs"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, pretrained_embeddings, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "\n",
        "        # Stacking two additional GRU layers\n",
        "        self.gru1 = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.gru3 = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        # Forward pass through the first GRU layer\n",
        "        output, hidden = self.gru1(embedded)\n",
        "        # Forward pass through the second GRU layer\n",
        "        output, hidden = self.gru2(output)\n",
        "        # Forward pass through the third GRU layer\n",
        "        output, hidden = self.gru3(output)\n",
        "\n",
        "        return output, hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4IeDDIEeaKs"
      },
      "source": [
        "#**The Decoder**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wkcQW6A-eaKs"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, pretrained_embeddings, num_layers=1):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "\n",
        "        # Stacking two additional GRU layers\n",
        "        self.gru1 = nn.GRU(hidden_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        # Additional linear layers\n",
        "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None  # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        embedded = self.embedding(input)\n",
        "        output = F.relu(embedded)\n",
        "\n",
        "        # Forward pass through the first GRU layer\n",
        "        output, hidden = self.gru1(output, hidden)\n",
        "        # Forward pass through the second GRU layer\n",
        "        output, hidden = self.gru2(output, hidden)\n",
        "\n",
        "        # Apply linear transformations\n",
        "        output = F.relu(self.linear1(output))\n",
        "        output = self.linear2(output)\n",
        "\n",
        "        return output, hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dssojz9YeaKs"
      },
      "source": [
        "#**Attention Decoder**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "79gpp3qheaKt"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, pretrained_embeddings, num_layers=1, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "\n",
        "        # Stacking two additional GRU layers\n",
        "        self.gru1 = nn.GRU(2 * hidden_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        # Additional linear layers\n",
        "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        # Forward pass through the first GRU layer\n",
        "        output, hidden = self.gru1(input_gru, hidden)\n",
        "        # Forward pass through the second GRU layer\n",
        "        output, hidden = self.gru2(output, hidden)\n",
        "\n",
        "        # Apply linear transformations\n",
        "        output = F.relu(self.linear1(output))\n",
        "        output = self.linear2(output)\n",
        "\n",
        "        return output, hidden, attn_weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training**"
      ],
      "metadata": {
        "id": "aULtGxsU0CPU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "B5lMN15meaKt"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'swe', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yhx4nr2eaKt"
      },
      "source": [
        "#**Training the Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V1rKle8JeaKt"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwdEbYaXeaKt"
      },
      "source": [
        "This is a helper function to print time elapsed and estimated time\n",
        "remaining given the current time and progress %.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OsDexAbMeaKt"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq8f-97seaKt"
      },
      "source": [
        "The whole training process looks like this:\n",
        "\n",
        "-   Start a timer\n",
        "-   Initialize optimizers and criterion\n",
        "-   Create set of training pairs\n",
        "-   Start empty losses array for plotting\n",
        "\n",
        "Then we call `train` many times and occasionally print the progress (%\n",
        "of examples, time so far, estimated time) and average loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Deky7ZkNeaKt"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfCgYETgeaKu"
      },
      "source": [
        "Plotting results\n",
        "================\n",
        "\n",
        "Plotting is done with matplotlib, using the array of loss values\n",
        "`plot_losses` saved while training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LoEzjeO7eaKu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViiO2gq8eaKu"
      },
      "source": [
        "#**Evaluation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q9h8bbtheaKu"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJrXlvn6eaKu"
      },
      "source": [
        "We can evaluate random sentences from the training set and print out the\n",
        "input, target, and output to make some subjective quality judgements:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rpH8-OhreaKu"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VePVLF6CeaKu"
      },
      "source": [
        "#**Training and Evaluating**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_lang.n_words, output_lang)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awN2MVXNGaee",
        "outputId": "93911a8a-9bee-4abb-d1c9-46deb93577cf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2079 <__main__.Lang object at 0x7af840e62a70>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gjIyTp58eaK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e11debf-7a69-43c3-9199-d5f6fbfbe968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 40314 sentence pairs\n",
            "Trimmed to 3017 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "swe 2079\n",
            "eng 1777\n",
            "0m 18s (- 4m 36s) (5 6%) 2.2845\n",
            "0m 32s (- 3m 47s) (10 12%) 1.6815\n",
            "0m 46s (- 3m 22s) (15 18%) 1.4298\n",
            "1m 0s (- 3m 2s) (20 25%) 1.2073\n",
            "1m 15s (- 2m 45s) (25 31%) 0.9620\n",
            "1m 29s (- 2m 29s) (30 37%) 0.7129\n",
            "1m 44s (- 2m 13s) (35 43%) 0.5384\n",
            "1m 58s (- 1m 58s) (40 50%) 0.4194\n",
            "2m 12s (- 1m 42s) (45 56%) 0.3303\n",
            "2m 26s (- 1m 27s) (50 62%) 0.2489\n",
            "2m 40s (- 1m 13s) (55 68%) 0.1825\n",
            "2m 55s (- 0m 58s) (60 75%) 0.1340\n",
            "3m 9s (- 0m 43s) (65 81%) 0.0995\n",
            "3m 23s (- 0m 29s) (70 87%) 0.0808\n",
            "3m 37s (- 0m 14s) (75 93%) 0.0746\n",
            "3m 51s (- 0m 0s) (80 100%) 0.0641\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 300\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size, pretrained_embeddings).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, pretrained_embeddings).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oHYu1dAeaK1"
      },
      "source": [
        "Set dropout layers to `eval` mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8AND2uFSeaK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102b6304-802d-4561-c331-687ed3266337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> hon ar valdigt duktig pa att imitera sin larare\n",
            "= she is very good at imitating her teacher\n",
            "< she is very good at imitating her teacher <EOS>\n",
            "\n",
            "> jag gor mina laxor\n",
            "= i m doing my homework\n",
            "< i m fine thanks for asking <EOS>\n",
            "\n",
            "> ni ar for aggressiva\n",
            "= you re too aggressive\n",
            "< you re too late <EOS>\n",
            "\n",
            "> han ar bra pa att dyka\n",
            "= he is good at diving\n",
            "< he is good at imitating her irish accent <EOS>\n",
            "\n",
            "> han ar inte snall mot henne\n",
            "= he is not kind to her\n",
            "< he is not kind to her <EOS>\n",
            "\n",
            "> jag gar till min mormors hus\n",
            "= i m going to my grandmother s\n",
            "< i m going to my grandmother s <EOS>\n",
            "\n",
            "> han ar en lognare\n",
            "= he s a liar\n",
            "< he s bad <EOS>\n",
            "\n",
            "> du ar inte rik\n",
            "= you re not rich\n",
            "< you re not one of that <EOS>\n",
            "\n",
            "> jag ar bra pa mitt jobb\n",
            "= i m good at my job\n",
            "< i m good at my parents <EOS>\n",
            "\n",
            "> jag laddar ner bilderna\n",
            "= i am downloading the images\n",
            "< i m only be a rest <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}